# Testing and Development Strategy

> [!NOTE]
> This document focuses on **testing methodology**. For broader engineering standards, see [RULES.md](RULES.md).

## Tooling

- Vitest (current)

If/when this repo adds these layers, document the concrete tooling in the same PR:

- HTTP E2E: Supertest (planned)
- UI E2E: Playwright (planned)
- Mutation testing: Stryker (planned)

## Philosophy

- ALWAYS test behaviour, NEVER test implementation
- **Strictness:** No permissive fallbacks and no partial success. If behavior is unsupported, tests must assert a fail-fast error with helpful context.
- **Prove System Behaviour**: Tests must prove that the system behaves correctly from the user's or caller's perspective, rather than verifying that specific code paths are executed.
- **Never Constrain Implementation**: Tests must never be coupled to the internal implementation details. Refactoring internals should never break a test if the external behaviour remains the same.
- **Tests Must Be Useful**: Every test must provide value by proving a specific requirement or preventing a specific regression. If a test doesn't prove anything useful, delete it.
- Prefer pure functions and unit tests
- Always use TDD at ALL levels (unit, integration, E2E)
- Prefer unit tests over integration tests
- Prefer integration tests over E2E tests
- ALL IO MUST BE MOCKED, except in E2E tests
- NEVER create complex mocks, use simple mocks passed as arguments to the function under test. Complex mocks result in testing the mocks, and indicate that product code needs refactoring and simplification in order to be easily testable.
- ALL mocks MUST be simple fakes, passed as arguments to the function under test.
- NEVER test external functionality, that is not under our control
- NEVER add complex logic to tests - it risks testing the test code rather than the code under test
- Each proof should happen ONCE - repeated proofs are fragile and waste resources
- NEVER manipulate global state in tests — no `process.env` mutations, no `vi.stubGlobal`, no `vi.doMock`. Product code must accept configuration as parameters.

## Rules

- **TDD** - ALWAYS use TDD, prefer pure functions and unit tests. Write tests **FIRST**. Red (failing _test_), Green (passing test, because product code is created at this point, _not before_), Refactor (improve the product code implementation, know that the _behaviour_ at the interface will remain proven by the test)
- **Test real behaviour, not implementation details** - We should be able to change _how_ something works without breaking the test that proves _that_ it works.
- **Test to interfaces, not internals** - Tests should be written to the interfaces, not the internals. Closely related to test behaviour not implementation.
- **No useless tests** - Each test must prove something useful about the product code. If a test is only testing the test or mocks, delete it.
- **Do not test types** - Tests are for logic, types are explored through creating tests, but types cannot be tested. If test only tests types, delete it.
- **KISS: No complex logic in tests** - Complexity in tests is a signal that we need to step back and simplify, the code and the test.
- **KISS: No complex mocks** - Mocks should be simple and focused, no complex logic in mocks, or we risk testing the mocks rather than the code. Complex mocks are a signal that we need to step back and simplify the code or our approach.
- **No skipped tests (except upstream quarantines)** — Fix our pipeline defects or delete the tests. Do not use `it.skip` to mask our own regressions. If a test _must_ be skipped because it exposes an upstream library defect beyond our control while maintaining coverage for expansion, it must be explicitly segregated (e.g., passing `DEFECT_FIXTURES` to `it.skip.each()`) to keep CI stable without relaxing main strictness rules.

## Definitions

### System Architecture Components

- Pure function: A function that has no side effects and returns the same result for the same input. Pure functions are the building blocks of all code. Pure functions have unit tests. Naming convention: `*.unit.test.ts`.
- Integration point: A point in the code where multiple units are brought together to effect change in the larger system. Typically this is where IO interfaces are injected as arguments to functions, and where other configuration occurs. Integration points define boundaries of responsibility. Integration points have integration tests. Naming convention: `*.integration.test.ts`.
- System: The complete MCP server exposed via stdio transport. Systems have E2E tests. Naming convention: `*.e2e.test.ts`.

### Test Types

#### In-process tests

In-process tests are tests that validate **code imported into the test process**. The code under test runs in the same process as the test runner. They are fast, specific, and do not produce side effects. These tests are about testing CODE, not testing RUNNING SYSTEMS.

- **Unit test**: A test that verifies the behaviour of a single PURE function in isolation. Unit tests DO NOT trigger IO, have NO side effects, and contain NO MOCKS. Unit tests are automatically run in CI/CD.
- **Integration test**: A test that verifies the behaviour of a collection of units **working together as code**, NOT a running system. Integration tests still import and test code directly within the test process. They DO NOT trigger IO, have NO side effects and can contain SIMPLE mocks which must be injected as arguments to the function under test. Integration tests are automatically run in CI/CD and include MCP protocol compliance testing. **Important**: Integration tests are NOT about testing a deployed or running system - they test how multiple code units integrate when imported and called directly.

#### Out-of-process tests

Out-of-process tests are tests that validate a running _system_, the tests and the system run in _separate processes_. They are slower, are less specific in the causes of issues but cast a wider net, and may produce side effects locally and in external systems.

- **E2E test**: A test that verifies the behaviour of a running system. E2E tests CAN trigger File System and STDIO IO but NOT network IO, DO have side effects, and contain minimal mocks, largely around network IO. These constrains are to allow the E2E tests to be safely run in CI/CD.

- **Smoke test**: A test that verifies the behaviour of a running system, locally or deployed. Smoke tests CAN trigger all IO types, DO have side effects, and DO NOT contain mocks.

#### Common Misconception: Integration Tests

**WRONG Understanding (Common but Incorrect):**

```typescript
// ❌ This is NOT an integration test - it's an E2E test
describe('API Integration Test', () => {
  it('should call the deployed API', async () => {
    const response = await fetch('http://localhost:3000/api/users');
    // Testing a RUNNING SYSTEM over HTTP
  });
});
```

**CORRECT Understanding (Our Definition):**

```typescript
// ✅ This IS an integration test - testing code units working together
import { UserService } from './user-service';
import { DatabaseAdapter } from './database-adapter';

describe('UserService Integration Test', () => {
  it('should retrieve users through the adapter', () => {
    const mockDb = { query: () => [{ id: 1, name: 'Alice' }] };
    const adapter = new DatabaseAdapter(mockDb); // Simple mock injected
    const service = new UserService(adapter);

    const users = service.getAllUsers();
    // Testing how CODE UNITS integrate, not a running system
    expect(users).toHaveLength(1);
  });
});
```

The key distinction: Integration tests import and test code directly. They never spawn processes, make network calls, or test deployed systems.

### Design Approaches

- Test Driven Development (TDD): Write tests before writing code at ALL levels. Tests PROVE correctness and specify desired behaviour.
- Behaviour Driven Development (BDD): Write integration and E2E tests before writing code. These tests PROVE we are creating the **desired behaviour and impact** at the integration point and system level.

## TDD at All Levels

### TDD is Not Just for Unit Tests

**Critical Rule**: TDD applies to unit, integration, AND E2E tests. Each level of tests MUST be written to specify the desired behaviour, BEFORE the implementation is created or changed.

### Unit Test TDD (Micro-level)

**Cycle**: Red → Green → Refactor

1. **RED**: Write a unit test for a pure function that doesn't exist yet. Run the test. It MUST fail.
2. **GREEN**: Write the minimal implementation to make the test pass. Run the test. It MUST pass.
3. **REFACTOR**: Improve the implementation without changing behaviour. Tests MUST remain green.

**Example**:

```typescript
// 1. RED - Write test first
describe('calculateTotal', () => {
  it('sums array of numbers', () => {
    expect(calculateTotal([1, 2, 3])).toBe(6);
  });
});
// Run test → FAILS (function doesn't exist)

// 2. GREEN - Minimal implementation
function calculateTotal(numbers: number[]): number {
  return numbers.reduce((sum, n) => sum + n, 0);
}
// Run test → PASSES

// 3. REFACTOR - Improve (if needed)
// Tests remain green
```

### Integration Test TDD (Component-level)

**Cycle**: Red → Green → Refactor

1. **RED**: Write integration test specifying how units work together. Run test. It MUST fail.
2. **GREEN**: Implement units and wire them together. Run test. It MUST pass.
3. **REFACTOR**: Improve integration without changing behaviour. Tests MUST remain green.

**Example**:

```typescript
// 1. RED - Write integration test first
describe('createMcpRouter', () => {
  it('should skip auth for discovery methods', async () => {
    const mockAuth = vi.fn();
    const router = createMcpRouter({ auth: mockAuth });
    const { req, res, next } = createMocks({
      body: { method: 'tools/list' },
    });

    await router(req, res, next);

    expect(next).toHaveBeenCalled();
    expect(mockAuth).not.toHaveBeenCalled();
  });
});
// Run test → FAILS (createMcpRouter doesn't exist)

// 2. GREEN - Implement router
export function createMcpRouter(options: McpRouterOptions): RequestHandler {
  return (req, res, next) => {
    const method = getMethodFromBody(req.body);
    if (method && isDiscoveryMethod(method)) {
      next();
      return;
    }
    options.auth(req, res, next);
  };
}
// Run test → PASSES

// 3. REFACTOR - Extract helper functions, improve clarity
// Tests remain green
```

### E2E Test TDD (System-level)

**Cycle**: Red → Green → Refactor

**CRITICAL**: E2E tests are SPECIFICATIONS of system behaviour. When changing system behaviour, update E2E tests FIRST.

1. **RED**: Write E2E test specifying desired system behaviour. Run test against existing system. It MUST fail (old behaviour).
2. **GREEN**: Modify system implementation (often involving multiple units/integrations). Run test. It MUST pass (new behaviour).
3. **REFACTOR**: Improve system internals without changing external behaviour. E2E tests MUST remain green.

**Example - Correct TDD Sequence**:

```typescript
// SCENARIO: We want discovery methods to work WITHOUT authentication

// 1. RED - Write E2E test FIRST specifying NEW behaviour
describe('MCP Server E2E', () => {
  it('allows tools/list without authentication', async () => {
    const response = await request(server).post('/mcp').send({ method: 'tools/list' });

    expect(response.status).toBe(200); // NEW expected behaviour
    expect(response.body).toHaveProperty('result');
  });

  it('requires auth for protected tools', async () => {
    const response = await request(server)
      .post('/mcp')
      .send({ method: 'tools/call', params: { name: 'get-key-stages' } });

    expect(response.status).toBe(401); // Still required
  });
});
// Run E2E test → FAILS (current system requires auth for ALL methods)

// 2. GREEN - Now implement changes
// - Write unit tests for isDiscoveryMethod() (RED → GREEN)
// - Write integration tests for createMcpRouter() (RED → GREEN)
// - Wire router into application
// Run E2E test → PASSES (system now has new behaviour)

// 3. REFACTOR - Improve internals
// E2E tests remain green
```

**Example - WRONG Sequence (What We Did)**:

```typescript
// ❌ VIOLATION: Updated implementation first, E2E tests after

// 1. Wrote new integration tests for router (good!)
// 2. Implemented router (implementation-first, not test-first at E2E level)
// 3. Discovered E2E tests now fail (they specified OLD behaviour)
// 4. Need to update E2E tests (should have been step 1!)

// This is NOT TDD at the E2E level
```

### TDD Rule Summary

| Test Level      | What It Specifies       | When to Write                   | RED Phase                    |
| --------------- | ----------------------- | ------------------------------- | ---------------------------- |
| **Unit**        | Pure function behaviour | Before function exists          | No function → test fails     |
| **Integration** | How units work together | Before integration exists       | Units not wired → test fails |
| **E2E**         | System behaviour        | Before system behaviour changes | Old behaviour → test fails   |

**Key Insight**: If tests lag behind code at ANY level, TDD was not followed at that level.

## Common TDD Violations and Fixes

### Violation 1: Writing Code Before Tests

❌ **Wrong**:

```typescript
// Write implementation first
function add(a: number, b: number) {
  return a + b;
}

// Then write test
it('adds numbers', () => expect(add(1, 2)).toBe(3));
```

✅ **Correct**:

```typescript
// Write test FIRST
it('adds numbers', () => expect(add(1, 2)).toBe(3));
// Run → FAILS (add doesn't exist)

// Then write implementation
function add(a: number, b: number) {
  return a + b;
}
// Run → PASSES
```

### Violation 2: Updating E2E Tests After Implementation

❌ **Wrong**:

```typescript
// 1. Implement new feature in code
// 2. Run E2E tests → they fail (old spec)
// 3. Update E2E tests to match new implementation
```

✅ **Correct**:

```typescript
// 1. Update E2E tests to specify new behaviour FIRST
// 2. Run E2E tests → they fail (feature not implemented)
// 3. Implement feature
// 4. Run E2E tests → they pass
```

### Violation 3: Tests That Only Pass With Current Implementation

❌ **Wrong**:

```typescript
// Test that knows too much about implementation
it('calls internal method', () => {
  const spy = vi.spyOn(service, '_privateMethod');
  service.doThing();
  expect(spy).toHaveBeenCalled(); // Breaks if we refactor
});
```

✅ **Correct**:

```typescript
// Test that specifies behaviour
it('produces correct result', () => {
  const result = service.doThing();
  expect(result).toBe(expectedValue); // Survives refactoring
});
```

## Development Workflow

- ALWAYS USE TDD at ALL levels
- Use Vitest for all in-process tests (unit + integration)
- Use the MCP client SDK for MCP protocol E2E tests
- Use the canonical mocking approaches for the testing tools in use for a given test
- Tests live next to the code they test, not in a `test` directory
  - Unit tests live next to the pure function file containing the functions they test. They MUST end in `*.unit.test.ts`
  - Integration tests live next to the integration point file containing the integration points they test. They MUST end in `*.integration.test.ts`
  - E2E tests are an exception and live in the `e2e-tests` directory. This is because they test a running _system_ rather than importing code to test. They MUST end in `*.e2e.test.ts`

## When Behaviour Changes

**Rule**: Update tests at the SAME level as the behaviour change FIRST, before changing implementation.

- **Pure function behaviour changes**: Update unit tests FIRST
- **Integration behaviour changes**: Update integration tests FIRST
- **System behaviour changes**: Update E2E tests FIRST

**Example**:

- If discovery methods should work without auth (system behaviour change)
- Update E2E tests to specify this (RED phase)
- Then implement changes in code (GREEN phase)
- Then refactor internals (REFACTOR phase, tests stay green)

This ensures tests remain specifications, not just regression checks.

---

## Acceptance Test Layers

These layers define the structured acceptance criteria for the Castr pipeline. Each layer targets a specific correctness dimension.

### 1) Strict Spec Validation (Input Gate)

- Reject invalid version syntax and wrong-version fields (3.0-only vs 3.1-only)
- Reject unresolved `$ref`, invalid HTTP methods, missing required fields
- Reject disallowed constructs per version (e.g., `nullable` in 3.1, `jsonSchemaDialect` in 3.0)

### 2) IR Completeness and Fidelity

- Every required OpenAPI 3.0/3.1 field is represented in IR
- Lossless transform execution for supported fields (no omissions or merges)
- IR schema metadata supports strict Zod output (required, nullable, dependency graph)

### 3) OpenAPI Transform Validation (Sample Input)

- OpenAPI input → IR → OpenAPI output matches normalized 3.1 expectations
- Upgrades (3.0 → 3.1) are strictly standards-compliant
- No weak/tolerance assertions in transform scenarios (`<=`, "at least", skip-on-error behavior)
- Parse failures are assertions, not control flow: no early returns on parse errors; assert zero parse errors with fixture-scoped context before downstream structural checks

### 4) Writer Outputs (Zod + Metadata)

- Zod schemas use `.strict()` for all object schemas
- Required vs optional properties exactly match the spec
- Literal types preserved in metadata maps and endpoint definitions
- No `as`, `any`, `!`, or other type escape hatches

### 5) Determinism

- Run generation twice per fixture and assert byte-for-byte equality
- Stable ordering in components, endpoints, and metadata maps

### 6) Oak Harness Integration

- Validate against `verify-castr-fixtures.ts` outputs
- Run the Oak adapter replacement scenario (no changes beyond import paths)
- Use `castr-bundle` only if required by the harness; verify shape strictly

---

## Fixture Sources & Matrix

### Fixture Provenance

| Source                     | Description                                                             |
| -------------------------- | ----------------------------------------------------------------------- |
| Oak SDK-decorated fixtures | Ground truth input + expected outputs                                   |
| Castr normalized fixtures  | Transform-validation IR artifacts (incl. round-trip/idempotence proofs) |
| Synthetic fixtures         | OpenAPI-TS-inspired edge cases recreated in-house (never copied)        |

### Fixture Matrix (Strict-Only)

| Category                                        | Source            | Primary Checks                                       |
| ----------------------------------------------- | ----------------- | ---------------------------------------------------- |
| Oak SDK-decorated core                          | Oak fixtures      | Full output equivalence, strictness, determinism     |
| OpenAPI 3.0 → 3.1 upgrades                      | Synthetic         | Correct upgrades, strict rejection of invalid syntax |
| Composition (allOf/oneOf/anyOf, discriminators) | Synthetic         | IR fidelity, Zod output shape                        |
| Nullable and unions                             | Synthetic         | Type array handling, no `nullable` in 3.1            |
| Callbacks and webhooks                          | Synthetic + Castr | IR coverage, OpenAPI writer                          |
| Headers, links, examples, pathItems             | Synthetic         | IR completeness and writer preservation              |
| Security schemes (oauth2, mutualTLS, etc.)      | Synthetic         | Strict validation + output mapping                   |
| External refs and bundling                      | Synthetic         | Ref resolution and cycle handling                    |

### Licensing and Provenance

- Do not copy third-party specs from OpenAPI-TS; recreate synthetic equivalents
- If reusing MIT-licensed content, confirm the license for specific files and add `docs/THIRD_PARTY_NOTICES.md` with attribution
- Record fixture provenance (synthetic vs first-party) in test metadata

---

## Authoritative References

| Document                                                            | Purpose                                     |
| ------------------------------------------------------------------- | ------------------------------------------- |
| `.agent/directives/requirements.md`                                 | Strict validation and OpenAPI 3.0/3.1 rules |
| `.agent/directives/RULES.md`                                        | Strictness, fail-fast, TDD discipline       |
| `research/oak-open-curriculum-sdk/castr-requests/README.md`         | Oak contract shape                          |
| `research/oak-open-curriculum-sdk/castr-requests/oak-principles.md` | Type discipline                             |
| `research/feature-parity/*`                                         | Parity gaps and integration targets         |
| `research/openapi-ts/openapi-ts-comparison.md`                      | Fixture categories and edge cases           |
